{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    suffixesList = [\"්\", \"ා\", \"ැ\", \"ෑ\", \"ි\", \"ී\", \"ු\",\n",
    "                    \"ූ\", \"ෙ\", \"ේ\", \"ෛ\", \"ො\", \"ෝ\", \"ෞ\", \"ෘ\", \"ෲ\"]\n",
    "    tokens = []\n",
    "    li = 1\n",
    "    while li < len(text):\n",
    "        prevChar, currentChar = text[li - 1], text[li]\n",
    "        if(currentChar == '\\u200d'):\n",
    "            if(li < len(text) - 1):\n",
    "                if(prevChar == suffixesList[0] and (text[li + 1] == 'ර' or text[li + 1] == 'ය' or text[li + 1] == 'ද')):\n",
    "                    tokens.append(tokens.pop()+currentChar+text[li + 1])\n",
    "                    li += 1\n",
    "        elif(currentChar in suffixesList):\n",
    "            if(li != 1):\n",
    "                tokens.append(f\"{tokens.pop()}{currentChar}\")\n",
    "            else:\n",
    "                tokens.append(f\"{prevChar}{currentChar}\")\n",
    "        else:\n",
    "            if(li == 1):\n",
    "                tokens.append(prevChar)\n",
    "            tokens.append(currentChar)\n",
    "        li += 1\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "letters = set()\n",
    "with open('c:\\\\Users\\\\Yasith\\\\Documents\\\\GitHub\\\\FYP-Omega\\\\Data/combined all names - cleaned.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        for sub in line.split():\n",
    "            sub = tokenize(sub)\n",
    "            if(len(sub) > 1):\n",
    "                letters.update(sub)\n",
    "with open('data.json', 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(list(letters), outfile, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "602"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data.json', 'r', encoding='utf-8') as json_file:\n",
    "    letters = json.load(json_file)\n",
    "len(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8452/995999915.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mletters\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "random.randint(0,len(letters-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yasith\\AppData\\Local\\Temp/ipykernel_8452/1271081678.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  error['original'] = error['original'].str.replace(r'\\n', '')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "uni = open('c:\\\\Users\\\\Yasith\\\\Documents\\\\GitHub\\\\FYP-Omega\\\\Data/combined all names - cleaned - test.txt', 'r', encoding='utf-8').readlines()\n",
    "error = pd.DataFrame()\n",
    "error['original']=uni\n",
    "error['original'] = error['original'].str.replace(r'\\n', '')\n",
    "er = []\n",
    "\n",
    "for name in uni:\n",
    "    tokenName = tokenize(name.replace(r'\\n', ''))\n",
    "    tokenName[random.randint(0,len(tokenName)-1)] = letters[random.randint(0,len(letters)-1)]\n",
    "    er.append(''.join(tokenName))\n",
    "\n",
    "error['random Error'] = er\n",
    "error.to_csv('Random errors.csv',encoding='utf-8-sig',index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "627a90b54e6da1f209648a2c9c5f7e12610f05c4265361c3c1b7d26135e86100"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
